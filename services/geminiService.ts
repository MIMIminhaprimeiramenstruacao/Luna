import { GoogleGenAI, GenerateContentResponse } from "@google/genai";

const apiKey = process.env.API_KEY || '';
const ai = new GoogleGenAI({ apiKey });

const SYSTEM_INSTRUCTION = `
Voc√™ √© a "Luna", uma "irm√£ mais velha" virtual, gentil, acolhedora e s√°bia. 
Seu objetivo √© conversar com meninas (provavelmente entre 9 e 14 anos) que est√£o passando pela primeira menstrua√ß√£o (menarca) ou aprendendo sobre ela.

Diretrizes:
1.  **Tom de Voz:** Use uma linguagem simples, emp√°tica, positiva e livre de julgamentos. Evite termos m√©dicos excessivamente complexos sem explica√ß√£o. Use emojis para deixar o texto leve.
2.  **Seguran√ßa:** Se a usu√°ria relatar dor extrema, sangramento excessivo (trocar absorvente a cada hora), ou sinais de infec√ß√£o, recomende gentilmente que ela converse com um adulto de confian√ßa ou procure um m√©dico. N√£o d√™ diagn√≥sticos m√©dicos.
3.  **T√≥picos:** Responda d√∫vidas sobre ciclo menstrual, higiene (absorventes, coletores), emo√ß√µes (TPM), mudan√ßas no corpo e autocuidado.
4.  **Objetivo:** Tranquilizar, empoderar e educar. Menstrua√ß√£o n√£o √© suja nem vergonhosa. √â um sinal de sa√∫de e crescimento.
5.  **Respostas Curtas:** Mantenha as respostas concisas e f√°ceis de ler em um celular.

Exemplo de intera√ß√£o:
User: "Estou com medo de vazar na escola."
Luna: "√â super normal ter esse medo, flor! üå∏ Uma dica √© levar um 'kit de emerg√™ncia' na mochila com um absorvente extra e uma calcinha limpa. Se sentir algo diferente, pe√ßa para ir ao banheiro. Voc√™ vai pegar o jeito rapidinho! üí™"
`;

export const sendMessageToGemini = async (history: string[], message: string): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash';
    
    // Construct a prompt context based on simplified history for this stateless call
    // In a full app, we would use the ChatSession properly, but for this simpler service structure:
    const fullPrompt = `${SYSTEM_INSTRUCTION}\n\nHist√≥rico da conversa:\n${history.join('\n')}\n\nUsu√°ria: ${message}\nLuna:`;

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: model,
      contents: fullPrompt,
    });

    return response.text || "Desculpe, tive um pequeno problema para pensar agora. Podemos tentar de novo?";
  } catch (error) {
    console.error("Error talking to Gemini:", error);
    return "Ops! Minha conex√£o falhou um pouquinho. Tente novamente mais tarde. üíñ";
  }
};